{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Data Extraction - Lab Answers\n",
    "\n",
    "## Lab 2: Membership Inference - Exercise Answer\n",
    "\n",
    "### Exercise: Improve Attack with Shadow Models\n",
    "\n",
    "**Task**: Implement a more sophisticated membership inference attack using shadow models.\n",
    "\n",
    "**Answer**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target model...\n",
      "Target model trained\n",
      "\n",
      "Training 5 shadow models...\n",
      "  Shadow model 1/5 trained\n",
      "  Shadow model 2/5 trained\n",
      "  Shadow model 3/5 trained\n",
      "  Shadow model 4/5 trained\n",
      "  Shadow model 5/5 trained\n",
      "Training attack model...\n",
      "  Attack model training accuracy: 0.999\n",
      "\n",
      "Testing membership inference...\n",
      "\n",
      "Results:\n",
      "Training data identified as members: 48.0%\n",
      "Test data identified as non-members: 42.0%\n",
      "Overall attack accuracy: 45.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ShadowModelAttack:\n",
    "    \"\"\"\n",
    "    Membership inference using shadow models.\n",
    "    \n",
    "    The attacker trains shadow models on similar data to learn\n",
    "    the behavior difference between members and non-members.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_shadow_models=5):\n",
    "        self.num_shadow_models = num_shadow_models\n",
    "        self.shadow_models = []\n",
    "        self.attack_model = None\n",
    "        \n",
    "    def train_shadow_models(self, shadow_data, shadow_labels, model_architecture):\n",
    "        \"\"\"\n",
    "        Train multiple shadow models on different data splits.\n",
    "        \n",
    "        Args:\n",
    "            shadow_data: Data similar to target model's training data\n",
    "            shadow_labels: Labels for shadow data\n",
    "            model_architecture: Function that returns a new model instance\n",
    "        \"\"\"\n",
    "        print(f\"Training {self.num_shadow_models} shadow models...\")\n",
    "        \n",
    "        for i in range(self.num_shadow_models):\n",
    "            # Split data for this shadow model\n",
    "            train_idx = np.random.choice(len(shadow_data), \n",
    "                                        size=len(shadow_data)//2, \n",
    "                                        replace=False)\n",
    "            test_idx = np.setdiff1d(np.arange(len(shadow_data)), train_idx)\n",
    "            \n",
    "            # Create and train shadow model\n",
    "            shadow_model = model_architecture()\n",
    "            \n",
    "            # Train on subset (these are \"members\")\n",
    "            train_data = shadow_data[train_idx]\n",
    "            train_labels = shadow_labels[train_idx]\n",
    "            \n",
    "            # Simple training loop\n",
    "            optimizer = torch.optim.Adam(shadow_model.parameters(), lr=0.001)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            shadow_model.train()\n",
    "            for epoch in range(10):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = shadow_model(train_data)\n",
    "                loss = criterion(outputs, train_labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            self.shadow_models.append({\n",
    "                'model': shadow_model,\n",
    "                'train_idx': train_idx,\n",
    "                'test_idx': test_idx\n",
    "            })\n",
    "            \n",
    "            print(f\"  Shadow model {i+1}/{self.num_shadow_models} trained\")\n",
    "    \n",
    "    def extract_features(self, model, data):\n",
    "        \"\"\"\n",
    "        Extract features from model predictions.\n",
    "        \n",
    "        Features include:\n",
    "        - Prediction confidence\n",
    "        - Entropy of prediction\n",
    "        - Top-k probabilities\n",
    "        - Prediction correctness\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(data)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Feature 1: Max probability (confidence)\n",
    "            max_prob = probs.max(dim=1)[0]\n",
    "            \n",
    "            # Feature 2: Entropy\n",
    "            entropy = -(probs * torch.log(probs + 1e-10)).sum(dim=1)\n",
    "            \n",
    "            # Feature 3: Top-3 probabilities\n",
    "            top3_probs = torch.topk(probs, k=min(3, probs.shape[1]), dim=1)[0]\n",
    "            \n",
    "            # Combine features\n",
    "            features = torch.cat([\n",
    "                max_prob.unsqueeze(1),\n",
    "                entropy.unsqueeze(1),\n",
    "                top3_probs\n",
    "            ], dim=1)\n",
    "            \n",
    "        return features.cpu().numpy()\n",
    "    \n",
    "    def train_attack_model(self, shadow_data, shadow_labels):\n",
    "        \"\"\"\n",
    "        Train attack model to distinguish members from non-members.\n",
    "        \"\"\"\n",
    "        print(\"Training attack model...\")\n",
    "        \n",
    "        # Collect training data for attack model\n",
    "        attack_features = []\n",
    "        attack_labels = []  # 1 = member, 0 = non-member\n",
    "        \n",
    "        for shadow_info in self.shadow_models:\n",
    "            shadow_model = shadow_info['model']\n",
    "            train_idx = shadow_info['train_idx']\n",
    "            test_idx = shadow_info['test_idx']\n",
    "            \n",
    "            # Extract features for members (training data)\n",
    "            member_features = self.extract_features(\n",
    "                shadow_model, \n",
    "                shadow_data[train_idx]\n",
    "            )\n",
    "            attack_features.append(member_features)\n",
    "            attack_labels.extend([1] * len(member_features))\n",
    "            \n",
    "            # Extract features for non-members (test data)\n",
    "            non_member_features = self.extract_features(\n",
    "                shadow_model,\n",
    "                shadow_data[test_idx]\n",
    "            )\n",
    "            attack_features.append(non_member_features)\n",
    "            attack_labels.extend([0] * len(non_member_features))\n",
    "        \n",
    "        # Combine all features\n",
    "        X = np.vstack(attack_features)\n",
    "        y = np.array(attack_labels)\n",
    "        \n",
    "        # Train attack classifier\n",
    "        self.attack_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        self.attack_model.fit(X, y)\n",
    "        \n",
    "        # Evaluate on training data\n",
    "        train_acc = self.attack_model.score(X, y)\n",
    "        print(f\"  Attack model training accuracy: {train_acc:.3f}\")\n",
    "    \n",
    "    def infer_membership(self, target_model, data):\n",
    "        \"\"\"\n",
    "        Infer whether data points were in target model's training set.\n",
    "        \n",
    "        Args:\n",
    "            target_model: The target model to attack\n",
    "            data: Data points to test\n",
    "        \n",
    "        Returns:\n",
    "            predictions: 1 = member, 0 = non-member\n",
    "            probabilities: Confidence scores\n",
    "        \"\"\"\n",
    "        # Extract features from target model\n",
    "        features = self.extract_features(target_model, data)\n",
    "        \n",
    "        # Use attack model to predict membership\n",
    "        predictions = self.attack_model.predict(features)\n",
    "        probabilities = self.attack_model.predict_proba(features)[:, 1]\n",
    "        \n",
    "        return predictions, probabilities\n",
    "\n",
    "# Example usage\n",
    "def create_simple_model():\n",
    "    \"\"\"Simple model architecture for demonstration\"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(10, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 2)\n",
    "    )\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Shadow data (attacker's auxiliary dataset)\n",
    "shadow_data = torch.randn(1000, 10)\n",
    "shadow_labels = torch.randint(0, 2, (1000,))\n",
    "\n",
    "# Target model's data\n",
    "target_train_data = torch.randn(500, 10)\n",
    "target_train_labels = torch.randint(0, 2, (500,))\n",
    "target_test_data = torch.randn(500, 10)\n",
    "target_test_labels = torch.randint(0, 2, (500,))\n",
    "\n",
    "# Train target model\n",
    "print(\"Training target model...\")\n",
    "target_model = create_simple_model()\n",
    "optimizer = torch.optim.Adam(target_model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "target_model.train()\n",
    "for epoch in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = target_model(target_train_data)\n",
    "    loss = criterion(outputs, target_train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Target model trained\\n\")\n",
    "\n",
    "# Perform shadow model attack\n",
    "attacker = ShadowModelAttack(num_shadow_models=5)\n",
    "attacker.train_shadow_models(shadow_data, shadow_labels, create_simple_model)\n",
    "attacker.train_attack_model(shadow_data, shadow_labels)\n",
    "\n",
    "# Test membership inference\n",
    "print(\"\\nTesting membership inference...\")\n",
    "\n",
    "# Test on training data (should predict member)\n",
    "train_predictions, train_probs = attacker.infer_membership(\n",
    "    target_model, target_train_data[:100]\n",
    ")\n",
    "train_accuracy = train_predictions.mean()\n",
    "\n",
    "# Test on test data (should predict non-member)\n",
    "test_predictions, test_probs = attacker.infer_membership(\n",
    "    target_model, target_test_data[:100]\n",
    ")\n",
    "test_accuracy = 1 - test_predictions.mean()\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"Training data identified as members: {train_accuracy:.1%}\")\n",
    "print(f\"Test data identified as non-members: {test_accuracy:.1%}\")\n",
    "print(f\"Overall attack accuracy: {(train_accuracy + test_accuracy) / 2:.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Key Improvements**:\n",
    "1. **Shadow Models**: Learn membership patterns from similar models\n",
    "2. **Feature Engineering**: Extract multiple features from predictions\n",
    "3. **ML-based Attack**: Use classifier instead of simple threshold\n",
    "4. **Ensemble Approach**: Multiple shadow models improve robustness\n",
    "\n",
    "**Attack Success Factors**:\n",
    "- Quality of shadow data (similarity to target training data)\n",
    "- Number of shadow models\n",
    "- Feature selection\n",
    "- Target model overfitting\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Lab 3: Model Inversion - Exercise Answer\n",
    "\n",
    "### Exercise: Improve Reconstruction with Regularization\n",
    "\n",
    "**Task**: Add regularization to make reconstructed images more realistic.\n",
    "\n",
    "**Answer**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Model Inversion with Regularization:\n",
      "============================================================\n",
      "Step    0: Loss=  6.4611, Class= 0.1155, TV=633.1109, L2=14.5115, Conf=0.090\n",
      "Step  200: Loss=  4.1327, Class= 0.0896, TV=403.0000, L2=13.0767, Conf=0.092\n",
      "Step  400: Loss=  4.1327, Class= 0.0896, TV=403.0000, L2=13.0767, Conf=0.092\n",
      "Step  600: Loss=  4.1327, Class= 0.0896, TV=403.0000, L2=13.0767, Conf=0.092\n",
      "Step  800: Loss=  4.1327, Class= 0.0896, TV=403.0000, L2=13.0767, Conf=0.092\n",
      "\n",
      "\n",
      "Advanced Model Inversion:\n",
      "============================================================\n",
      "Step    0: Total= 0.9253, Conf=0.090\n",
      "Step  300: Total= 0.2017, Conf=0.090\n",
      "Step  600: Total= 0.1685, Conf=0.090\n",
      "Step  900: Total= 0.1468, Conf=0.090\n",
      "Step 1200: Total= 0.1379, Conf=0.090\n",
      "\n",
      "✓ Saved comparison to model_inversion_comparison.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def improved_model_inversion(model, target_class, steps=2000, lr=0.1,\n",
    "                            tv_weight=0.01, l2_weight=0.001):\n",
    "    \"\"\"\n",
    "    Model inversion with regularization for realistic reconstructions.\n",
    "    \n",
    "    Args:\n",
    "        model: Target model\n",
    "        target_class: Class to reconstruct\n",
    "        steps: Optimization steps\n",
    "        lr: Learning rate\n",
    "        tv_weight: Total variation regularization weight\n",
    "        l2_weight: L2 regularization weight\n",
    "    \n",
    "    Returns:\n",
    "        reconstructed_image: Reconstructed input\n",
    "    \"\"\"\n",
    "    # Detect device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize with random noise\n",
    "    x = torch.randn(1, 1, 28, 28, requires_grad=True, device=device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam([x], lr=lr)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.5)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_x = x.clone()\n",
    "    \n",
    "    for step in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Ensure valid pixel range\n",
    "        x_clamped = torch.clamp(x, 0, 1)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(x_clamped)\n",
    "        \n",
    "        # Classification loss (maximize target class probability)\n",
    "        class_loss = -output[0, target_class]\n",
    "        \n",
    "        # Total Variation (TV) regularization\n",
    "        # Encourages smooth images\n",
    "        tv_loss = (\n",
    "            torch.sum(torch.abs(x_clamped[:, :, :, :-1] - x_clamped[:, :, :, 1:])) +\n",
    "            torch.sum(torch.abs(x_clamped[:, :, :-1, :] - x_clamped[:, :, 1:, :]))\n",
    "        )\n",
    "        \n",
    "        # L2 regularization (prefer smaller pixel values)\n",
    "        l2_loss = torch.norm(x_clamped)\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = class_loss + tv_weight * tv_loss + l2_weight * l2_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Track best reconstruction\n",
    "        if total_loss.item() < best_loss:\n",
    "            best_loss = total_loss.item()\n",
    "            best_x = x_clamped.detach().clone()\n",
    "        \n",
    "        # Logging\n",
    "        if step % 200 == 0:\n",
    "            confidence = torch.softmax(output, dim=1)[0, target_class].item()\n",
    "            print(f\"Step {step:4d}: Loss={total_loss.item():8.4f}, \"\n",
    "                  f\"Class={class_loss.item():7.4f}, TV={tv_loss.item():7.4f}, \"\n",
    "                  f\"L2={l2_loss.item():7.4f}, Conf={confidence:.3f}\")\n",
    "    \n",
    "    return best_x\n",
    "\n",
    "# Advanced version with multiple regularization techniques\n",
    "def advanced_model_inversion(model, target_class, steps=3000):\n",
    "    \"\"\"\n",
    "    Advanced model inversion with multiple regularization techniques.\n",
    "    \"\"\"\n",
    "    # Detect device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize with better starting point (mean of training data)\n",
    "    x = torch.randn(1, 1, 28, 28, device=device) * 0.1 + 0.5\n",
    "    x.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.Adam([x], lr=0.1)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=steps)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_x = x.clone()\n",
    "    \n",
    "    for step in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Clamp to valid range\n",
    "        x_clamped = torch.sigmoid(x)  # Smooth clamping\n",
    "        \n",
    "        # Get model output\n",
    "        output = model(x_clamped)\n",
    "        \n",
    "        # 1. Classification loss\n",
    "        class_loss = -output[0, target_class]\n",
    "        \n",
    "        # 2. Total Variation (smoothness)\n",
    "        tv_h = torch.sum(torch.abs(x_clamped[:, :, 1:, :] - x_clamped[:, :, :-1, :]))\n",
    "        tv_w = torch.sum(torch.abs(x_clamped[:, :, :, 1:] - x_clamped[:, :, :, :-1]))\n",
    "        tv_loss = tv_h + tv_w\n",
    "        \n",
    "        # 3. L2 norm (prefer smaller values)\n",
    "        l2_loss = torch.norm(x_clamped - 0.5)  # Center around 0.5\n",
    "        \n",
    "        # 4. Entropy regularization (encourage confident predictions)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        entropy = -(probs * torch.log(probs + 1e-10)).sum()\n",
    "        \n",
    "        # Adaptive weights\n",
    "        tv_weight = 0.02 * (1 - step / steps)  # Decrease over time\n",
    "        l2_weight = 0.001\n",
    "        entropy_weight = 0.01\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = (class_loss + \n",
    "                     tv_weight * tv_loss + \n",
    "                     l2_weight * l2_loss + \n",
    "                     entropy_weight * entropy)\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if total_loss.item() < best_loss:\n",
    "            best_loss = total_loss.item()\n",
    "            best_x = x_clamped.detach().clone()\n",
    "        \n",
    "        if step % 300 == 0:\n",
    "            conf = torch.softmax(output, dim=1)[0, target_class].item()\n",
    "            print(f\"Step {step:4d}: Total={total_loss.item():7.4f}, \"\n",
    "                  f\"Conf={conf:.3f}\")\n",
    "    \n",
    "    return best_x\n",
    "\n",
    "# Example usage\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Create and \"train\" model (simplified)\n",
    "model = SimpleClassifier()\n",
    "model.eval()\n",
    "\n",
    "print(\"Basic Model Inversion with Regularization:\")\n",
    "print(\"=\" * 60)\n",
    "reconstructed_basic = improved_model_inversion(\n",
    "    model, target_class=5, steps=1000\n",
    ")\n",
    "\n",
    "print(\"\\n\\nAdvanced Model Inversion:\")\n",
    "print(\"=\" * 60)\n",
    "reconstructed_advanced = advanced_model_inversion(\n",
    "    model, target_class=5, steps=1500\n",
    ")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(reconstructed_basic.cpu().squeeze(), cmap='gray')\n",
    "axes[0].set_title('Basic Regularization')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(reconstructed_advanced.cpu().squeeze(), cmap='gray')\n",
    "axes[1].set_title('Advanced Regularization')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_inversion_comparison.png')\n",
    "print(\"\\n✓ Saved comparison to model_inversion_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Regularization Techniques**:\n",
    "\n",
    "1. **Total Variation (TV)**:\n",
    "   - Encourages smooth, natural-looking images\n",
    "   - Penalizes large differences between adjacent pixels\n",
    "   - Reduces noise and artifacts\n",
    "\n",
    "2. **L2 Regularization**:\n",
    "   - Prevents extreme pixel values\n",
    "   - Keeps reconstruction close to mean\n",
    "   - Improves stability\n",
    "\n",
    "3. **Entropy Regularization**:\n",
    "   - Encourages confident predictions\n",
    "   - Helps optimization converge\n",
    "   - Reduces ambiguous reconstructions\n",
    "\n",
    "4. **Adaptive Weights**:\n",
    "   - Start with strong regularization\n",
    "   - Gradually reduce to allow fine details\n",
    "   - Balance between realism and accuracy\n",
    "\n",
    "**Results**:\n",
    "- More realistic reconstructions\n",
    "- Smoother images\n",
    "- Better visual quality\n",
    "- Still reveals private information!\n",
    "\n",
    "**Defense Implications**:\n",
    "- Regularization makes attack harder but not impossible\n",
    "- Need stronger defenses (differential privacy, output perturbation)\n",
    "- Model inversion is a serious privacy threat\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Module 4 exercises demonstrate:\n",
    "- Shadow models significantly improve membership inference\n",
    "- Regularization creates more realistic model inversions\n",
    "- Privacy attacks are sophisticated and effective\n",
    "- Strong defenses are needed to protect training data\n",
    "\n",
    "Continue to Module 5 for poisoning attacks!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
