{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial NLP: Text-Based Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using Apple Silicon GPU (MPS)\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Setup and Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Detect device (supports CUDA, Apple Silicon MPS, and CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"✓ Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"✓ Using Apple Silicon GPU (MPS)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"ℹ Using CPU\")\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ nltk already installed\n",
      "Downloading WordNet data...\n",
      "✓ WordNet data downloaded\n",
      "Note: spacy not installed (optional - only needed for NER attack examples)\n",
      "To install: pip install spacy && python -m spacy download en_core_web_sm\n",
      "✓ textattack already installed\n",
      "\n",
      "✓ Core packages ready!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for this notebook\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
    "\n",
    "# Check and install nltk\n",
    "try:\n",
    "    import nltk\n",
    "    print(\"✓ nltk already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing nltk...\")\n",
    "    install_package('nltk')\n",
    "    import nltk\n",
    "    print(\"✓ nltk installed\")\n",
    "\n",
    "# Download WordNet data\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "    print(\"✓ WordNet data already downloaded\")\n",
    "except LookupError:\n",
    "    print(\"Downloading WordNet data...\")\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('omw-1.4', quiet=True)\n",
    "    print(\"✓ WordNet data downloaded\")\n",
    "\n",
    "# Check spacy (optional - only needed for NER examples)\n",
    "try:\n",
    "    import spacy\n",
    "    print(\"✓ spacy already installed\")\n",
    "except ImportError:\n",
    "    print(\"Note: spacy not installed (optional - only needed for NER attack examples)\")\n",
    "    print(\"To install: pip install spacy && python -m spacy download en_core_web_sm\")\n",
    "\n",
    "# Check textattack (optional)\n",
    "try:\n",
    "    import textattack\n",
    "    print(\"✓ textattack already installed\")\n",
    "except ImportError:\n",
    "    print(\"Note: textattack not installed (optional - for framework examples)\")\n",
    "    print(\"To install: pip install textattack\")\n",
    "\n",
    "print(\"\\n✓ Core packages ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "Adversarial NLP focuses on crafting adversarial examples for natural language processing models. Unlike image attacks, text attacks face unique challenges: discrete input space, semantic constraints, and human readability requirements. This document covers comprehensive adversarial techniques for NLP systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "\n",
    "- Understand unique challenges of adversarial NLP\n",
    "- Implement character-level attacks\n",
    "- Execute word-level substitution attacks\n",
    "- Perform sentence-level perturbations\n",
    "- Use semantic-preserving transformations\n",
    "- Evaluate attack success and imperceptibility\n",
    "- Design robust NLP defenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why NLP Attacks Are Different\n",
    "\n",
    "\n",
    "### Challenges Unique to Text\n",
    "\n",
    "**1. Discrete Input Space**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image pixel value: [127.5 127.5 127.5]\n",
      "Text: hello\n",
      "Cannot add 0.001 to 'h' - must replace entire character\n"
     ]
    }
   ],
   "source": [
    "# Example: Discrete vs Continuous Input Space\n",
    "import numpy as np\n",
    "\n",
    "# Images: Continuous pixel values [0, 255]\n",
    "image = np.zeros((224, 224, 3))  # Create example image\n",
    "image[0,0] = 127.5  # Can use gradients - continuous values\n",
    "print(f\"Image pixel value: {image[0,0]}\")\n",
    "\n",
    "# Text: Discrete tokens\n",
    "text = \"hello\"  # Can't do: text[0] = \"h\" + 0.001\n",
    "# Must substitute entire tokens\n",
    "print(f\"Text: {text}\")\n",
    "print(\"Cannot add 0.001 to 'h' - must replace entire character\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Semantic Constraints**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:    I love this movie\n",
      "Perturbed 1: I lové this movie (noticeable)\n",
      "Perturbed 2: I hate this movie (meaning changed)\n"
     ]
    }
   ],
   "source": [
    "# Example: Semantic Constraints in Text\n",
    "\n",
    "# Image: Small pixel changes often imperceptible\n",
    "# Text: Single character change can destroy meaning\n",
    "\n",
    "original = \"I love this movie\"\n",
    "# Small change with accent - noticeable\n",
    "perturbed1 = \"I lové this movie\"\n",
    "# Word substitution - changes meaning completely\n",
    "perturbed2 = \"I hate this movie\"\n",
    "\n",
    "print(f\"Original:    {original}\")\n",
    "print(f\"Perturbed 1: {perturbed1} (noticeable)\")\n",
    "print(f\"Perturbed 2: {perturbed2} (meaning changed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Human Readability**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad attack (obvious):\n",
      "  I l0v3 th!$ m0v!3\n",
      "\n",
      "Good attack (natural):\n",
      "  I adore this film\n"
     ]
    }
   ],
   "source": [
    "# Example: Human Readability Requirement\n",
    "\n",
    "# Attack must fool model AND remain readable to humans\n",
    "bad_attack = \"I l0v3 th!$ m0v!3\"  # Obvious attack - leetspeak\n",
    "good_attack = \"I adore this film\"  # Natural, semantic-preserving\n",
    "\n",
    "print(\"Bad attack (obvious):\")\n",
    "print(f\"  {bad_attack}\")\n",
    "print(\"\\nGood attack (natural):\")\n",
    "print(f\"  {good_attack}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack Taxonomy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "Adversarial NLP Attacks\n",
    "├── Character-Level\n",
    "│   ├── Character Insertion\n",
    "│   ├── Character Deletion\n",
    "│   ├── Character Substitution\n",
    "│   ├── Visual Similarity (homoglyphs)\n",
    "│   └── Keyboard Typos\n",
    "├── Word-Level\n",
    "│   ├── Synonym Substitution\n",
    "│   ├── Word Insertion\n",
    "│   ├── Word Deletion\n",
    "│   ├── Word Reordering\n",
    "│   └── Embedding-Based Substitution\n",
    "├── Sentence-Level\n",
    "│   ├── Paraphrasing\n",
    "│   ├── Back-Translation\n",
    "│   ├── Sentence Reordering\n",
    "│   └── Style Transfer\n",
    "└── Semantic-Preserving\n",
    "    ├── Named Entity Substitution\n",
    "    ├── Contextual Substitution\n",
    "    ├── Grammar-Preserving Changes\n",
    "    └── Meaning-Preserving Transformations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Example: Homoglyph Attack\n",
    "\n",
    "Let's test the homoglyph attack on a real sentiment model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentiment model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original:    This is a great product\n",
      "  Prediction: POSITIVE (1.000)\n",
      "\n",
      "Adversarial: Thіs is а grеat prοduсt\n",
      "  Prediction: NEGATIVE (0.981)\n",
      "\n",
      "Attack success: True\n",
      "Confidence change: 0.019\n"
     ]
    }
   ],
   "source": [
    "# Working Example: Homoglyph Attack\n",
    "from transformers import pipeline\n",
    "import random\n",
    "\n",
    "# Load sentiment model\n",
    "print(\"Loading sentiment model...\")\n",
    "sentiment = pipeline('sentiment-analysis', \n",
    "                    model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "def homoglyph_attack(text):\n",
    "    \"\"\"Replace characters with visually similar Unicode characters\"\"\"\n",
    "    homoglyphs = {\n",
    "        'a': ['а', 'ɑ'],  # Cyrillic a, Latin alpha\n",
    "        'e': ['е', 'ė'],  # Cyrillic e, Latin e with dot\n",
    "        'o': ['о', 'ο'],  # Cyrillic o, Greek omicron\n",
    "        'i': ['і', 'ı'],  # Cyrillic i, dotless i\n",
    "        'c': ['с'],       # Cyrillic s\n",
    "    }\n",
    "    \n",
    "    adversarial_text = text\n",
    "    for char, replacements in homoglyphs.items():\n",
    "        if char in adversarial_text.lower():\n",
    "            replacement = random.choice(replacements)\n",
    "            # Replace first occurrence\n",
    "            adversarial_text = adversarial_text.replace(char, replacement, 1)\n",
    "    \n",
    "    return adversarial_text\n",
    "\n",
    "# Test the attack\n",
    "original = \"This is a great product\"\n",
    "adversarial = homoglyph_attack(original)\n",
    "\n",
    "print(f\"\\nOriginal:    {original}\")\n",
    "orig_result = sentiment(original)[0]\n",
    "print(f\"  Prediction: {orig_result['label']} ({orig_result['score']:.3f})\")\n",
    "\n",
    "print(f\"\\nAdversarial: {adversarial}\")\n",
    "adv_result = sentiment(adversarial)[0]\n",
    "print(f\"  Prediction: {adv_result['label']} ({adv_result['score']:.3f})\")\n",
    "\n",
    "print(f\"\\nAttack success: {orig_result['label'] != adv_result['label']}\")\n",
    "print(f\"Confidence change: {abs(orig_result['score'] - adv_result['score']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Example: Synonym Substitution Attack\n",
    "\n",
    "Let's implement a simple synonym substitution attack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:    This movie is great and entertaining\n",
      "  Prediction: POSITIVE (1.000)\n",
      "\n",
      "Adversarial: This movie is majuscule and nurse\n",
      "  Prediction: NEGATIVE (0.994)\n",
      "\n",
      "Synonyms used:\n",
      "  great → majuscule\n",
      "  entertaining → nurse\n"
     ]
    }
   ],
   "source": [
    "# Working Example: Synonym Substitution Attack\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_synonyms(word):\n",
    "    \"\"\"Get synonyms for a word using WordNet\"\"\"\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonym = lemma.name().replace('_', ' ')\n",
    "            if synonym.lower() != word.lower():\n",
    "                synonyms.add(synonym)\n",
    "    return list(synonyms)\n",
    "\n",
    "def simple_synonym_attack(text, target_words):\n",
    "    \"\"\"Replace target words with synonyms\"\"\"\n",
    "    words = text.split()\n",
    "    adversarial_words = words.copy()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() in target_words:\n",
    "            synonyms = get_synonyms(word.lower())\n",
    "            if synonyms:\n",
    "                adversarial_words[i] = synonyms[0]\n",
    "    \n",
    "    return ' '.join(adversarial_words)\n",
    "\n",
    "# Test the attack\n",
    "original = \"This movie is great and entertaining\"\n",
    "adversarial = simple_synonym_attack(original, ['great', 'entertaining'])\n",
    "\n",
    "print(f\"Original:    {original}\")\n",
    "orig_result = sentiment(original)[0]\n",
    "print(f\"  Prediction: {orig_result['label']} ({orig_result['score']:.3f})\")\n",
    "\n",
    "print(f\"\\nAdversarial: {adversarial}\")\n",
    "adv_result = sentiment(adversarial)[0]\n",
    "print(f\"  Prediction: {adv_result['label']} ({adv_result['score']:.3f})\")\n",
    "\n",
    "print(f\"\\nSynonyms used:\")\n",
    "print(f\"  great → {adversarial.split()[3]}\")\n",
    "print(f\"  entertaining → {adversarial.split()[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character-Level Attacks\n",
    "\n",
    "\n",
    "### Attack 1: Character Substitution\n",
    "\n",
    "**Concept**: Replace characters with visually similar ones (homoglyphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:    This is a great product\n",
      "Adversarial: Th1s is а grēat ρrоduсt\n"
     ]
    }
   ],
   "source": [
    "def homoglyph_attack(text):\n",
    "    \"\"\"\n",
    "    Replace characters with visually similar Unicode characters\n",
    "    \"\"\"\n",
    "    homoglyphs = {\n",
    "        'a': ['а', 'ɑ', 'α'],  # Cyrillic a, Latin alpha, Greek alpha\n",
    "        'e': ['е', 'ė', 'ē'],  # Cyrillic e, Latin e with dot\n",
    "        'o': ['о', 'ο', '0'],  # Cyrillic o, Greek omicron, zero\n",
    "        'i': ['і', 'ı', '1'],  # Cyrillic i, dotless i, one\n",
    "        'c': ['с', 'ϲ'],       # Cyrillic s, Greek lunate sigma\n",
    "        'p': ['р', 'ρ'],       # Cyrillic r, Greek rho\n",
    "        'x': ['х', 'χ'],       # Cyrillic h, Greek chi\n",
    "    }\n",
    "    \n",
    "    adversarial_text = text\n",
    "    for char, replacements in homoglyphs.items():\n",
    "        if char in adversarial_text:\n",
    "            # Replace with random homoglyph\n",
    "            replacement = random.choice(replacements)\n",
    "            adversarial_text = adversarial_text.replace(char, replacement, 1)\n",
    "    \n",
    "    return adversarial_text\n",
    "\n",
    "# Example\n",
    "original = \"This is a great product\"\n",
    "adversarial = homoglyph_attack(original)\n",
    "print(f\"Original:    {original}\")\n",
    "print(f\"Adversarial: {adversarial}\")\n",
    "# Output: \"This is а greаt produсt\" (contains Cyrillic characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack 2: Character Insertion/Deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_insertion_attack(text, model, num_insertions=3):\n",
    "    \"\"\"\n",
    "    Insert characters to fool model while maintaining readability\n",
    "    \"\"\"\n",
    "    import string\n",
    "    \n",
    "    best_text = text\n",
    "    best_score = model.predict_proba(text)[target_class]\n",
    "    \n",
    "    for _ in range(num_insertions):\n",
    "        # Try inserting each character at each position\n",
    "        for pos in range(len(text)):\n",
    "            for char in string.ascii_lowercase + ' ':\n",
    "                candidate = text[:pos] + char + text[pos:]\n",
    "                score = model.predict_proba(candidate)[target_class]\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_text = candidate\n",
    "                    best_score = score\n",
    "    \n",
    "    return best_text\n",
    "\n",
    "def char_deletion_attack(text, model):\n",
    "    \"\"\"\n",
    "    Delete characters to fool model\n",
    "    \"\"\"\n",
    "    best_text = text\n",
    "    best_score = model.predict_proba(text)[target_class]\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        candidate = text[:i] + text[i+1:]\n",
    "        score = model.predict_proba(candidate)[target_class]\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_text = candidate\n",
    "            best_score = score\n",
    "    \n",
    "    return best_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack 3: Keyboard Typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyboard_typo_attack(text):\n",
    "    \"\"\"\n",
    "    Simulate realistic keyboard typos\n",
    "    \"\"\"\n",
    "    # QWERTY keyboard adjacency\n",
    "    keyboard_neighbors = {\n",
    "        'a': ['q', 'w', 's', 'z'],\n",
    "        'b': ['v', 'g', 'h', 'n'],\n",
    "        'c': ['x', 'd', 'f', 'v'],\n",
    "        # ... complete mapping\n",
    "    }\n",
    "    \n",
    "    words = text.split()\n",
    "    adversarial_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if random.random() < 0.3:  # 30% chance of typo\n",
    "            pos = random.randint(0, len(word)-1)\n",
    "            char = word[pos]\n",
    "            if char in keyboard_neighbors:\n",
    "                typo_char = random.choice(keyboard_neighbors[char])\n",
    "                word = word[:pos] + typo_char + word[pos+1:]\n",
    "        adversarial_words.append(word)\n",
    "    \n",
    "    return ' '.join(adversarial_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-Level Attacks\n",
    "\n",
    "\n",
    "### Attack 4: Synonym Substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation Note**: The above code uses helper functions like:\n",
    "\n",
    "```python\n",
    "get_word_importance(text, model)  # Compute importance scores\n",
    "get_synonyms(word)                # Get word synonyms\n",
    "is_attack_successful(...)         # Check if attack worked\n",
    "```\n",
    "\n",
    "These would need to be implemented based on your specific use case.\n",
    "See the working examples above for concrete implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack 5: Embedding-Based Substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation Note**: The above code uses helper functions like:\n",
    "\n",
    "```python\n",
    "get_word_importance(text, model)  # Compute importance scores\n",
    "get_synonyms(word)                # Get word synonyms\n",
    "is_attack_successful(...)         # Check if attack worked\n",
    "```\n",
    "\n",
    "These would need to be implemented based on your specific use case.\n",
    "See the working examples above for concrete implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack 6: Word Insertion/Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation Note**: The above code uses helper functions like:\n",
    "\n",
    "```python\n",
    "get_word_importance(text, model)  # Compute importance scores\n",
    "get_synonyms(word)                # Get word synonyms\n",
    "is_attack_successful(...)         # Check if attack worked\n",
    "```\n",
    "\n",
    "These would need to be implemented based on your specific use case.\n",
    "See the working examples above for concrete implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-Level Attacks\n",
    "\n",
    "\n",
    "### Attack 7: Paraphrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_attack(text, paraphrase_model):\n",
    "    \"\"\"\n",
    "    Generate paraphrases to fool model\n",
    "    \"\"\"\n",
    "    # Use T5 or BART for paraphrasing\n",
    "    from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "    \n",
    "    model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "    \n",
    "    # Generate paraphrases\n",
    "    input_text = f\"paraphrase: {text}\"\n",
    "    inputs = tokenizer(input_text, return_tensors='pt')\n",
    "    \n",
    "    # Generate multiple paraphrases\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        num_return_sequences=10,\n",
    "        num_beams=10,\n",
    "        max_length=100\n",
    "    )\n",
    "    \n",
    "    paraphrases = [\n",
    "        tokenizer.decode(output, skip_special_tokens=True)\n",
    "        for output in outputs\n",
    "    ]\n",
    "    \n",
    "    return paraphrases\n",
    "\n",
    "def select_best_paraphrase(paraphrases, target_model, target_class):\n",
    "    \"\"\"\n",
    "    Select paraphrase that best fools target model\n",
    "    \"\"\"\n",
    "    best_paraphrase = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for paraphrase in paraphrases:\n",
    "        score = target_model.predict_proba(paraphrase)[target_class]\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_paraphrase = paraphrase\n",
    "    \n",
    "    return best_paraphrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack 8: Back-Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translation_attack(text, intermediate_languages=['fr', 'de', 'es']):\n",
    "    \"\"\"\n",
    "    Translate to intermediate language and back to create adversarial text\n",
    "    \"\"\"\n",
    "    from transformers import MarianMTModel, MarianTokenizer\n",
    "    \n",
    "    adversarial_texts = []\n",
    "    \n",
    "    for lang in intermediate_languages:\n",
    "        # Translate to intermediate language\n",
    "        model_name = f'Helsinki-NLP/opus-mt-en-{lang}'\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "        \n",
    "        translated = model.generate(\n",
    "            **tokenizer(text, return_tensors='pt')\n",
    "        )\n",
    "        intermediate_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Translate back to English\n",
    "        model_name = f'Helsinki-NLP/opus-mt-{lang}-en'\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "        \n",
    "        back_translated = model.generate(\n",
    "            **tokenizer(intermediate_text, return_tensors='pt')\n",
    "        )\n",
    "        adversarial_text = tokenizer.decode(back_translated[0], skip_special_tokens=True)\n",
    "        \n",
    "        adversarial_texts.append(adversarial_text)\n",
    "    \n",
    "    return adversarial_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack 9: Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_transfer_attack(text, target_style='formal'):\n",
    "    \"\"\"\n",
    "    Change text style while preserving meaning\n",
    "    \"\"\"\n",
    "    # Use style transfer model\n",
    "    from transformers import pipeline\n",
    "    \n",
    "    style_transfer = pipeline('text-generation', model='style-transfer-model')\n",
    "    \n",
    "    prompt = f\"Rewrite in {target_style} style: {text}\"\n",
    "    adversarial_text = style_transfer(prompt)[0]['generated_text']\n",
    "    \n",
    "    return adversarial_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-Based NLP Attacks\n",
    "\n",
    "\n",
    "### Attack 10: HotFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotflip_attack(text, model, tokenizer, num_flips=3):\n",
    "    \"\"\"\n",
    "    HotFlip: Gradient-based character/word flips\n",
    "    \n",
    "    Reference: \"HotFlip: White-Box Adversarial Examples for Text Classification\"\n",
    "               (Ebrahimi et al., 2018)\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    input_ids = inputs['input_ids']\n",
    "    \n",
    "    # Enable gradients\n",
    "    embeddings = model.get_input_embeddings()\n",
    "    input_embeds = embeddings(input_ids)\n",
    "    input_embeds.requires_grad = True\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs_embeds=input_embeds)\n",
    "    loss = outputs.loss\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Get gradients\n",
    "    grad = input_embeds.grad\n",
    "    \n",
    "    # Compute flip scores for each position\n",
    "    vocab_size = embeddings.weight.shape[0]\n",
    "    flip_scores = torch.zeros(input_ids.shape[1], vocab_size)\n",
    "    \n",
    "    for i in range(input_ids.shape[1]):\n",
    "        # Compute score for flipping to each token\n",
    "        for j in range(vocab_size):\n",
    "            new_embed = embeddings.weight[j]\n",
    "            flip_scores[i, j] = torch.dot(\n",
    "                grad[0, i], \n",
    "                new_embed - input_embeds[0, i]\n",
    "            )\n",
    "    \n",
    "    # Select top flips\n",
    "    flat_scores = flip_scores.flatten()\n",
    "    top_flips = torch.topk(flat_scores, num_flips)\n",
    "    \n",
    "    # Apply flips\n",
    "    adversarial_ids = input_ids.clone()\n",
    "    for flip_idx in top_flips.indices:\n",
    "        pos = flip_idx // vocab_size\n",
    "        token = flip_idx % vocab_size\n",
    "        adversarial_ids[0, pos] = token\n",
    "    \n",
    "    adversarial_text = tokenizer.decode(adversarial_ids[0])\n",
    "    return adversarial_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack 11: TextFooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textfooler_attack(text, model, word_embeddings):\n",
    "    \"\"\"\n",
    "    TextFooler: Synonym substitution guided by importance\n",
    "    \n",
    "    Reference: \"Is BERT Really Robust?\" (Jin et al., 2020)\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    \n",
    "    # Step 1: Compute word importance\n",
    "    importance_scores = []\n",
    "    original_prob = model.predict_proba(text)[original_class]\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        # Delete word and measure impact\n",
    "        temp_text = ' '.join(words[:i] + words[i+1:])\n",
    "        temp_prob = model.predict_proba(temp_text)[original_class]\n",
    "        importance = original_prob - temp_prob\n",
    "        importance_scores.append(importance)\n",
    "    \n",
    "    # Step 2: Sort words by importance\n",
    "    sorted_indices = np.argsort(importance_scores)[::-1]\n",
    "    \n",
    "    # Step 3: Replace important words with synonyms\n",
    "    adversarial_words = words.copy()\n",
    "    \n",
    "    for idx in sorted_indices:\n",
    "        word = words[idx]\n",
    "        \n",
    "        # Get synonyms\n",
    "        synonyms = get_synonyms_from_embedding(word, word_embeddings)\n",
    "        \n",
    "        # Filter synonyms by semantic similarity and POS\n",
    "        filtered_synonyms = filter_synonyms(\n",
    "            word, synonyms, \n",
    "            similarity_threshold=0.7,\n",
    "            preserve_pos=True\n",
    "        )\n",
    "        \n",
    "        # Try each synonym\n",
    "        for synonym in filtered_synonyms:\n",
    "            candidate_words = adversarial_words.copy()\n",
    "            candidate_words[idx] = synonym\n",
    "            candidate_text = ' '.join(candidate_words)\n",
    "            \n",
    "            # Check if attack successful\n",
    "            pred_class = model.predict(candidate_text)\n",
    "            if pred_class != original_class:\n",
    "                return candidate_text\n",
    "            \n",
    "            # Update if improves attack\n",
    "            candidate_prob = model.predict_proba(candidate_text)[original_class]\n",
    "            if candidate_prob < original_prob:\n",
    "                adversarial_words[idx] = synonym\n",
    "                original_prob = candidate_prob\n",
    "    \n",
    "    return ' '.join(adversarial_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack 12: BERT-Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation Note**: The above code uses helper functions like:\n",
    "\n",
    "```python\n",
    "get_word_importance(text, model)  # Compute importance scores\n",
    "get_synonyms(word)                # Get word synonyms\n",
    "is_attack_successful(...)         # Check if attack worked\n",
    "```\n",
    "\n",
    "These would need to be implemented based on your specific use case.\n",
    "See the working examples above for concrete implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic-Preserving Attacks\n",
    "\n",
    "\n",
    "### Attack 13: Named Entity Substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_entity_attack(text, model):\n",
    "    \"\"\"\n",
    "    Replace named entities with similar entities\n",
    "    \"\"\"\n",
    "    import spacy\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Entity replacement dictionary\n",
    "    entity_replacements = {\n",
    "        'PERSON': ['John Smith', 'Jane Doe', 'Alex Johnson'],\n",
    "        'ORG': ['TechCorp', 'GlobalInc', 'MegaCorp'],\n",
    "        'GPE': ['New York', 'London', 'Tokyo'],\n",
    "        'DATE': ['yesterday', 'last week', 'recently'],\n",
    "    }\n",
    "    \n",
    "    adversarial_text = text\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in entity_replacements:\n",
    "            replacements = entity_replacements[ent.label_]\n",
    "            for replacement in replacements:\n",
    "                candidate = adversarial_text.replace(ent.text, replacement)\n",
    "                if is_attack_successful(model, candidate, target_class):\n",
    "                    return candidate\n",
    "    \n",
    "    return adversarial_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack 14: Contextual Word Substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextual_substitution_attack(text, model, context_model):\n",
    "    \"\"\"\n",
    "    Use contextual embeddings to find substitutions\n",
    "    \"\"\"\n",
    "    from transformers import BertModel, BertTokenizer\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    words = text.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        # Get contextual embedding\n",
    "        inputs = tokenizer(text, return_tensors='pt')\n",
    "        outputs = bert(**inputs)\n",
    "        word_embedding = outputs.last_hidden_state[0, i+1]  # +1 for [CLS]\n",
    "        \n",
    "        # Find words with similar contextual embeddings\n",
    "        candidates = find_contextually_similar_words(\n",
    "            word_embedding, bert, tokenizer\n",
    "        )\n",
    "        \n",
    "        # Try each candidate\n",
    "        for candidate in candidates:\n",
    "            test_words = words.copy()\n",
    "            test_words[i] = candidate\n",
    "            test_text = ' '.join(test_words)\n",
    "            \n",
    "            if is_attack_successful(model, test_text, target_class):\n",
    "                return test_text\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defense Mechanisms\n",
    "\n",
    "\n",
    "### Defense 1: Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training_nlp(model, train_data, attack_fn):\n",
    "    \"\"\"\n",
    "    Train model on adversarial examples\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for text, label in train_data:\n",
    "            # Generate adversarial example\n",
    "            adv_text = attack_fn(text, model)\n",
    "            \n",
    "            # Train on both clean and adversarial\n",
    "            for t in [text, adv_text]:\n",
    "                optimizer.zero_grad()\n",
    "                output = model(t)\n",
    "                loss = criterion(output, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defense 2: Input Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_defense(text):\n",
    "    \"\"\"\n",
    "    Normalize text to remove adversarial perturbations\n",
    "    \"\"\"\n",
    "    # Remove homoglyphs\n",
    "    text = remove_homoglyphs(text)\n",
    "    \n",
    "    # Spell check\n",
    "    text = spell_check(text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def remove_homoglyphs(text):\n",
    "    \"\"\"\n",
    "    Replace homoglyphs with standard characters\n",
    "    \"\"\"\n",
    "    homoglyph_map = {\n",
    "        'а': 'a',  # Cyrillic a -> Latin a\n",
    "        'е': 'e',  # Cyrillic e -> Latin e\n",
    "        'о': 'o',  # Cyrillic o -> Latin o\n",
    "        # ... complete mapping\n",
    "    }\n",
    "    \n",
    "    for homoglyph, standard in homoglyph_map.items():\n",
    "        text = text.replace(homoglyph, standard)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defense 3: Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_defense(text, models):\n",
    "    \"\"\"\n",
    "    Use ensemble of models for robustness\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        pred = model.predict(text)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Majority vote\n",
    "    final_prediction = max(set(predictions), key=predictions.count)\n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defense 4: Certified Robustness for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_bound_propagation_nlp(model, text, perturbation_set):\n",
    "    \"\"\"\n",
    "    Compute certified bounds for NLP model\n",
    "    \"\"\"\n",
    "    # Define perturbation set (e.g., all synonym substitutions)\n",
    "    perturbed_texts = generate_perturbation_set(text, perturbation_set)\n",
    "    \n",
    "    # Compute bounds\n",
    "    min_score = float('inf')\n",
    "    max_score = float('-inf')\n",
    "    \n",
    "    for perturbed_text in perturbed_texts:\n",
    "        score = model.predict_proba(perturbed_text)[predicted_class]\n",
    "        min_score = min(min_score, score)\n",
    "        max_score = max(max_score, score)\n",
    "    \n",
    "    # Check if certified\n",
    "    if min_score > 0.5:  # All perturbations predict same class\n",
    "        return True, (min_score, max_score)\n",
    "    else:\n",
    "        return False, (min_score, max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "\n",
    "### Attack Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack_success(attack_fn, test_data, model):\n",
    "    \"\"\"\n",
    "    Measure attack success rate\n",
    "    \"\"\"\n",
    "    successful_attacks = 0\n",
    "    total_attempts = 0\n",
    "    \n",
    "    for text, true_label in test_data:\n",
    "        # Original prediction\n",
    "        original_pred = model.predict(text)\n",
    "        \n",
    "        if original_pred == true_label:\n",
    "            # Generate adversarial example\n",
    "            adv_text = attack_fn(text, model)\n",
    "            adv_pred = model.predict(adv_text)\n",
    "            \n",
    "            if adv_pred != true_label:\n",
    "                successful_attacks += 1\n",
    "            \n",
    "            total_attempts += 1\n",
    "    \n",
    "    success_rate = successful_attacks / total_attempts\n",
    "    return success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_semantic_similarity(original_text, adversarial_text):\n",
    "    \"\"\"\n",
    "    Measure semantic similarity between original and adversarial\n",
    "    \"\"\"\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Get embeddings\n",
    "    emb1 = model.encode(original_text)\n",
    "    emb2 = model.encode(adversarial_text)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(emb1, emb2)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_perplexity(text, language_model):\n",
    "    \"\"\"\n",
    "    Measure text naturalness using perplexity\n",
    "    \"\"\"\n",
    "    from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "    \n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "    \n",
    "    perplexity = torch.exp(outputs.loss)\n",
    "    return perplexity.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and Frameworks\n",
    "\n",
    "\n",
    "### TextAttack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextAttack Framework (Optional)\n",
    "\n",
    "If you have `textattack` installed, here's how to use it:\n",
    "\n",
    "```python\n",
    "from textattack import Attack\n",
    "from textattack.attack_recipes import TextFoolerJin2019\n",
    "from textattack.datasets import HuggingFaceDataset\n",
    "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased-finetuned-sst-2-english'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'distilbert-base-uncased-finetuned-sst-2-english'\n",
    ")\n",
    "\n",
    "# Wrap for TextAttack\n",
    "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
    "dataset = HuggingFaceDataset('glue', 'sst2', split='test')\n",
    "\n",
    "# Create and run attack\n",
    "attack = TextFoolerJin2019.build(model_wrapper)\n",
    "results = attack.attack_dataset(dataset)\n",
    "```\n",
    "\n",
    "**Note**: This is optional and requires:\n",
    "```bash\n",
    "pip install textattack\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAttack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAttack Framework (Optional)\n",
    "\n",
    "If you have `OpenAttack` installed, here's how to use it:\n",
    "\n",
    "```python\n",
    "import OpenAttack as oa\n",
    "\n",
    "# Load victim model\n",
    "victim = oa.DataManager.loadVictim('BERT.SST')\n",
    "\n",
    "# Choose attack\n",
    "attacker = oa.attackers.PWWSAttacker()\n",
    "\n",
    "# Run attack\n",
    "attack_eval = oa.AttackEval(attacker, victim)\n",
    "attack_eval.eval(dataset, visualize=True)\n",
    "```\n",
    "\n",
    "**Note**: This is optional and requires `pip install OpenAttack`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Studies\n",
    "\n",
    "\n",
    "### Case 1: Sentiment Analysis Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original: \"This movie is great!\" → Positive\n",
    "# Attack: \"This movie is greαt!\" → Negative (homoglyph)\n",
    "# Success: Model fooled by single character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: Spam Detection Evasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original: \"Buy cheap viagra now!\" → Spam\n",
    "# Attack: \"Buy ch3ap v1agra n0w!\" → Not Spam\n",
    "# Success: Character substitution evades filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: Hate Speech Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original: \"I hate this group\" → Hate Speech\n",
    "# Attack: \"I dislike this group\" → Not Hate Speech\n",
    "# Success: Synonym substitution changes classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Discrete Challenge**: Text attacks face unique discrete input space\n",
    "2. **Multiple Levels**: Character, word, sentence-level attacks\n",
    "3. **Semantic Preservation**: Must maintain meaning and readability\n",
    "4. **Gradient-Based**: HotFlip, TextFooler, BERT-Attack\n",
    "5. **Defenses**: Preprocessing, adversarial training, ensembles\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "**For Attackers**:\n",
    "- Start with word-level attacks (most effective)\n",
    "- Preserve semantic similarity\n",
    "- Use gradient information when available\n",
    "- Combine multiple attack types\n",
    "\n",
    "**For Defenders**:\n",
    "- Input preprocessing and normalization\n",
    "- Adversarial training with diverse attacks\n",
    "- Ensemble methods\n",
    "- Monitor for unusual patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "### Key Papers\n",
    "\n",
    "1. \"HotFlip: White-Box Adversarial Examples for Text Classification\" (Ebrahimi et al., 2018)\n",
    "2. \"Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment\" (Jin et al., 2020)\n",
    "3. \"BERT-ATTACK: Adversarial Attack Against BERT Using BERT\" (Li et al., 2020)\n",
    "4. \"TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP\" (Morris et al., 2020)\n",
    "\n",
    "### Tools\n",
    "\n",
    "- [TextAttack](https://github.com/QData/TextAttack)\n",
    "- [OpenAttack](https://github.com/thunlp/OpenAttack)\n",
    "- [Adversarial-NLP](https://github.com/microsoft/Adversarial-NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "\n",
    "1. Complete [Lab 3: Text Adversarial Attacks](labs/lab3_text_attacks.ipynb)\n",
    "2. Experiment with TextAttack framework\n",
    "3. Implement custom NLP attacks\n",
    "4. Evaluate defense mechanisms\n",
    "5. Study latest NLP security research\n",
    "\n",
    "---\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐⭐ Advanced Level\n",
    "**Prerequisites**: NLP basics, transformers, PyTorch\n",
    "**Estimated Time**: 3-4 hours"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
