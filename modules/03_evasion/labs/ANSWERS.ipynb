{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Evasion Attacks - Lab Answers\n",
    "\n",
    "## Lab 1: Whitebox Evasion - Exercise Answer\n",
    "\n",
    "### Exercise: Implement C&W Attack\n",
    "\n",
    "**Task**: Research and implement the Carlini & Wagner attack.\n",
    "\n",
    "**Answer**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction: 111\n",
      "Iter 0: L2=112.0182, f=5.3782, pred=623\n",
      "Iter 100: L2=67.4974, f=0.0000, pred=112\n",
      "Iter 200: L2=29.8776, f=0.0000, pred=112\n",
      "Iter 300: L2=11.1530, f=0.0000, pred=112\n",
      "Iter 400: L2=4.5944, f=0.0000, pred=112\n",
      "\n",
      "Attack Results:\n",
      "Original class: 111\n",
      "Target class: 112\n",
      "Adversarial prediction: 112\n",
      "L2 perturbation: 2.6313\n",
      "Success: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def carlini_wagner_attack(model, image, target_class, c=1.0, kappa=0, \n",
    "                         max_iterations=1000, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Carlini & Wagner L2 attack\n",
    "    \n",
    "    Args:\n",
    "        model: Target model\n",
    "        image: Original image tensor\n",
    "        target_class: Target class for targeted attack\n",
    "        c: Confidence parameter\n",
    "        kappa: Confidence margin\n",
    "        max_iterations: Maximum optimization iterations\n",
    "        learning_rate: Learning rate for optimizer\n",
    "    \n",
    "    Returns:\n",
    "        adversarial_image: Adversarial example\n",
    "        perturbation: Perturbation added\n",
    "    \"\"\"\n",
    "    device = image.device\n",
    "    \n",
    "    # Initialize perturbation variable (in tanh space for box constraints)\n",
    "    w = torch.zeros_like(image, requires_grad=True)\n",
    "    optimizer = optim.Adam([w], lr=learning_rate)\n",
    "    \n",
    "    # Original prediction\n",
    "    with torch.no_grad():\n",
    "        original_pred = model(image).argmax()\n",
    "    \n",
    "    best_adv = image.clone()\n",
    "    best_l2 = float('inf')\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Convert w to adversarial image using tanh\n",
    "        # This ensures pixel values stay in valid range\n",
    "        adv_image = 0.5 * (torch.tanh(w) + 1)\n",
    "        \n",
    "        # Get model output\n",
    "        output = model(adv_image)\n",
    "        \n",
    "        # Calculate loss components\n",
    "        # L2 distance\n",
    "        l2_dist = torch.norm(adv_image - image)\n",
    "        \n",
    "        # Classification loss (encourage target class)\n",
    "        target_logit = output[0, target_class]\n",
    "        other_logits = torch.cat([output[0, :target_class], \n",
    "                                  output[0, target_class+1:]])\n",
    "        max_other_logit = other_logits.max()\n",
    "        \n",
    "        # f(x') = max(max(Z(x')_i for i != t) - Z(x')_t, -kappa)\n",
    "        f = torch.clamp(max_other_logit - target_logit, min=-kappa)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = l2_dist + c * f\n",
    "        \n",
    "        # Optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track best adversarial example\n",
    "        if f <= 0 and l2_dist < best_l2:\n",
    "            best_l2 = l2_dist.item()\n",
    "            best_adv = adv_image.detach().clone()\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            pred = output.argmax()\n",
    "            print(f\"Iter {iteration}: L2={l2_dist.item():.4f}, \"\n",
    "                  f\"f={f.item():.4f}, pred={pred.item()}\")\n",
    "    \n",
    "    perturbation = best_adv - image\n",
    "    \n",
    "    return best_adv, perturbation\n",
    "\n",
    "# Example usage\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Detect device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Load and preprocess image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create sample image (or load your own)\n",
    "img = torch.rand(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Get original prediction\n",
    "with torch.no_grad():\n",
    "    original_pred = model(img).argmax().item()\n",
    "    print(f\"Original prediction: {original_pred}\")\n",
    "\n",
    "# Run C&W attack\n",
    "target = (original_pred + 1) % 1000  # Target different class\n",
    "adv_img, perturbation = carlini_wagner_attack(\n",
    "    model, img, target, c=1.0, max_iterations=500\n",
    ")\n",
    "\n",
    "# Verify attack success\n",
    "with torch.no_grad():\n",
    "    adv_pred = model(adv_img).argmax().item()\n",
    "    l2_norm = torch.norm(perturbation).item()\n",
    "    \n",
    "print(f\"\\nAttack Results:\")\n",
    "print(f\"Original class: {original_pred}\")\n",
    "print(f\"Target class: {target}\")\n",
    "print(f\"Adversarial prediction: {adv_pred}\")\n",
    "print(f\"L2 perturbation: {l2_norm:.4f}\")\n",
    "print(f\"Success: {adv_pred == target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Key Concepts**:\n",
    "1. **Optimization-based**: Minimizes L2 distance while achieving misclassification\n",
    "2. **Tanh space**: Ensures pixel values stay in valid range [0, 1]\n",
    "3. **Confidence parameter (c)**: Balances perturbation size vs attack success\n",
    "4. **Kappa (κ)**: Confidence margin for more robust adversarial examples\n",
    "\n",
    "**Advantages over FGSM**:\n",
    "- Smaller perturbations\n",
    "- More effective\n",
    "- Can be targeted or untargeted\n",
    "- Better optimization\n",
    "\n",
    "**Disadvantages**:\n",
    "- Computationally expensive\n",
    "- Requires many iterations\n",
    "- Needs hyperparameter tuning\n",
    "\n",
    "---\n",
    "\n",
    "## Lab 2: Blackbox Evasion - Exercise Answer\n",
    "\n",
    "### Exercise: Targeted SimBA Attack\n",
    "\n",
    "**Task**: Modify SimBA attack to target a specific class.\n",
    "\n",
    "**Answer**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction: 111\n",
      "Initial: pred=111, target_score=-1.3784\n",
      "Iter 0: queries=2, pred=111, target_score=-1.3784, L2=0.0200\n",
      "Iter 10: queries=19, pred=111, target_score=-1.3779, L2=0.0662\n",
      "Iter 20: queries=36, pred=111, target_score=-1.3774, L2=0.0915\n",
      "Iter 30: queries=50, pred=111, target_score=-1.3769, L2=0.1111\n",
      "Iter 40: queries=67, pred=111, target_score=-1.3763, L2=0.1279\n",
      "Iter 50: queries=80, pred=111, target_score=-1.3757, L2=0.1427\n",
      "Iter 60: queries=93, pred=111, target_score=-1.3752, L2=0.1562\n",
      "Iter 70: queries=110, pred=111, target_score=-1.3747, L2=0.1687\n",
      "Iter 80: queries=127, pred=111, target_score=-1.3741, L2=0.1800\n",
      "Iter 90: queries=144, pred=111, target_score=-1.3734, L2=0.1908\n",
      "Iter 100: queries=159, pred=111, target_score=-1.3729, L2=0.2009\n",
      "Iter 110: queries=175, pred=111, target_score=-1.3725, L2=0.2107\n",
      "Iter 120: queries=191, pred=111, target_score=-1.3721, L2=0.2200\n",
      "Iter 130: queries=208, pred=111, target_score=-1.3713, L2=0.2290\n",
      "Iter 140: queries=221, pred=111, target_score=-1.3707, L2=0.2378\n",
      "Iter 150: queries=238, pred=111, target_score=-1.3702, L2=0.2461\n",
      "Iter 160: queries=254, pred=111, target_score=-1.3696, L2=0.2538\n",
      "Iter 170: queries=268, pred=111, target_score=-1.3692, L2=0.2616\n",
      "Iter 180: queries=284, pred=111, target_score=-1.3688, L2=0.2689\n",
      "Iter 190: queries=299, pred=111, target_score=-1.3682, L2=0.2764\n",
      "✗ Attack failed after 312 queries\n",
      "\n",
      "Final Results:\n",
      "Success: False\n",
      "Queries used: 312\n",
      "L2 distance: 0.2830\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def simba_targeted_attack(model, img_tensor, original_class, target_class, \n",
    "                         n_masks=1000, eta=0.01, max_queries=10000):\n",
    "    \"\"\"\n",
    "    Targeted SimBA (Simple Black-box Attack)\n",
    "    \n",
    "    Args:\n",
    "        model: Target model\n",
    "        img_tensor: Original image\n",
    "        original_class: Original predicted class\n",
    "        target_class: Desired target class\n",
    "        n_masks: Number of random masks to try\n",
    "        eta: Step size for perturbation\n",
    "        max_queries: Maximum number of queries\n",
    "    \n",
    "    Returns:\n",
    "        adv_img: Adversarial image\n",
    "        queries: Number of queries used\n",
    "        success: Whether attack succeeded\n",
    "    \"\"\"\n",
    "    device = img_tensor.device\n",
    "    adv_img = img_tensor.clone()\n",
    "    \n",
    "    # Track queries\n",
    "    queries = 0\n",
    "    \n",
    "    # Get initial prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(adv_img)\n",
    "        current_pred = output.argmax().item()\n",
    "        current_target_score = output[0, target_class].item()\n",
    "    \n",
    "    print(f\"Initial: pred={current_pred}, target_score={current_target_score:.4f}\")\n",
    "    \n",
    "    for iteration in range(max_queries // n_masks):\n",
    "        improved = False\n",
    "        \n",
    "        for _ in range(n_masks):\n",
    "            # Generate random mask\n",
    "            mask = torch.randn_like(adv_img)\n",
    "            mask = mask / torch.norm(mask)  # Normalize\n",
    "            \n",
    "            # Try positive perturbation\n",
    "            perturbed_pos = adv_img + eta * mask\n",
    "            perturbed_pos = torch.clamp(perturbed_pos, 0, 1)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output_pos = model(perturbed_pos)\n",
    "                pred_pos = output_pos.argmax().item()\n",
    "                target_score_pos = output_pos[0, target_class].item()\n",
    "            \n",
    "            queries += 1\n",
    "            \n",
    "            # Check if this improves target score\n",
    "            if target_score_pos > current_target_score:\n",
    "                adv_img = perturbed_pos\n",
    "                current_target_score = target_score_pos\n",
    "                current_pred = pred_pos\n",
    "                improved = True\n",
    "                \n",
    "                if current_pred == target_class:\n",
    "                    print(f\"✓ Success at query {queries}!\")\n",
    "                    return adv_img, queries, True\n",
    "                \n",
    "                break  # Move to next iteration\n",
    "            \n",
    "            # Try negative perturbation\n",
    "            perturbed_neg = adv_img - eta * mask\n",
    "            perturbed_neg = torch.clamp(perturbed_neg, 0, 1)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output_neg = model(perturbed_neg)\n",
    "                pred_neg = output_neg.argmax().item()\n",
    "                target_score_neg = output_neg[0, target_class].item()\n",
    "            \n",
    "            queries += 1\n",
    "            \n",
    "            if target_score_neg > current_target_score:\n",
    "                adv_img = perturbed_neg\n",
    "                current_target_score = target_score_neg\n",
    "                current_pred = pred_neg\n",
    "                improved = True\n",
    "                \n",
    "                if current_pred == target_class:\n",
    "                    print(f\"✓ Success at query {queries}!\")\n",
    "                    return adv_img, queries, True\n",
    "                \n",
    "                break\n",
    "        \n",
    "        if iteration % 10 == 0:\n",
    "            l2_dist = torch.norm(adv_img - img_tensor).item()\n",
    "            print(f\"Iter {iteration}: queries={queries}, pred={current_pred}, \"\n",
    "                  f\"target_score={current_target_score:.4f}, L2={l2_dist:.4f}\")\n",
    "        \n",
    "        if not improved:\n",
    "            # Reduce step size if no improvement\n",
    "            eta *= 0.9\n",
    "    \n",
    "    print(f\"✗ Attack failed after {queries} queries\")\n",
    "    return adv_img, queries, False\n",
    "\n",
    "# Example usage\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Detect device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Create sample image\n",
    "img = torch.rand(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Get original prediction\n",
    "with torch.no_grad():\n",
    "    original_pred = model(img).argmax().item()\n",
    "\n",
    "print(f\"Original prediction: {original_pred}\")\n",
    "\n",
    "# Choose target class\n",
    "target = (original_pred + 100) % 1000\n",
    "\n",
    "# Run targeted SimBA (with increased queries for better success rate)\n",
    "adv_img, queries, success = simba_targeted_attack(\n",
    "    model, img, original_pred, target, \n",
    "    n_masks=50, eta=0.02, max_queries=10000\n",
    ")\n",
    "\n",
    "# Results\n",
    "l2_dist = torch.norm(adv_img - img).item()\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Success: {success}\")\n",
    "print(f\"Queries used: {queries}\")\n",
    "print(f\"L2 distance: {l2_dist:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Key Modifications**:\n",
    "1. **Target Score Optimization**: Maximize logit for target class\n",
    "2. **Directional Search**: Try both +/- perturbations\n",
    "3. **Adaptive Step Size**: Reduce eta when stuck\n",
    "4. **Early Stopping**: Stop when target class is predicted\n",
    "\n",
    "**Comparison to Untargeted**:\n",
    "- Untargeted: Maximize any misclassification\n",
    "- Targeted: Maximize specific class score\n",
    "- Targeted is harder (requires more queries)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Lab 3: Text Attacks - Exercise Answers\n",
    "\n",
    "### Exercise 1: Keyboard Typo Attack\n",
    "\n",
    "**Task**: Implement keyboard typo attack with adjacent key substitutions.\n",
    "\n",
    "**Answer**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard Typo Attack Results:\n",
      "\n",
      "Original: This movie is absolutely terrible and boring\n",
      "  Prediction: NEGATIVE (1.000)\n",
      "Typo:     this movie is absolutely terrovle amd biring\n",
      "  Prediction: NEGATIVE (0.990)\n",
      "  Success: False\n",
      "\n",
      "Original: I hate this product, it's completely useless\n",
      "  Prediction: NEGATIVE (1.000)\n",
      "Typo:     I hzte this prpduct, it's comppetwly useless\n",
      "  Prediction: NEGATIVE (1.000)\n",
      "  Success: False\n",
      "\n",
      "Original: The service was awful and disappointing\n",
      "  Prediction: NEGATIVE (1.000)\n",
      "Typo:     the seevice was awful and diaapoounting\n",
      "  Prediction: NEGATIVE (0.989)\n",
      "  Success: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Keyboard layout (QWERTY)\n",
    "KEYBOARD_LAYOUT = {\n",
    "    'q': ['w', 'a'], 'w': ['q', 'e', 's'], 'e': ['w', 'r', 'd'],\n",
    "    'r': ['e', 't', 'f'], 't': ['r', 'y', 'g'], 'y': ['t', 'u', 'h'],\n",
    "    'u': ['y', 'i', 'j'], 'i': ['u', 'o', 'k'], 'o': ['i', 'p', 'l'],\n",
    "    'p': ['o', 'l'],\n",
    "    'a': ['q', 's', 'z'], 's': ['w', 'a', 'd', 'x'], 'd': ['e', 's', 'f', 'c'],\n",
    "    'f': ['r', 'd', 'g', 'v'], 'g': ['t', 'f', 'h', 'b'], 'h': ['y', 'g', 'j', 'n'],\n",
    "    'j': ['u', 'h', 'k', 'm'], 'k': ['i', 'j', 'l'], 'l': ['o', 'k', 'p'],\n",
    "    'z': ['a', 'x'], 'x': ['z', 's', 'c'], 'c': ['x', 'd', 'v'],\n",
    "    'v': ['c', 'f', 'b'], 'b': ['v', 'g', 'n'], 'n': ['b', 'h', 'm'],\n",
    "    'm': ['n', 'j']\n",
    "}\n",
    "\n",
    "def keyboard_typo_attack(text, typo_rate=0.1, preserve_first_last=True):\n",
    "    \"\"\"\n",
    "    Simulate keyboard typos by replacing characters with adjacent keys.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text\n",
    "        typo_rate: Probability of typo per character\n",
    "        preserve_first_last: Keep first and last char of each word\n",
    "    \n",
    "    Returns:\n",
    "        Text with typos\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    result_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) <= 2:\n",
    "            result_words.append(word)\n",
    "            continue\n",
    "        \n",
    "        chars = list(word.lower())\n",
    "        \n",
    "        # Determine which positions to modify\n",
    "        if preserve_first_last:\n",
    "            modifiable_positions = range(1, len(chars) - 1)\n",
    "        else:\n",
    "            modifiable_positions = range(len(chars))\n",
    "        \n",
    "        # Apply typos\n",
    "        for i in modifiable_positions:\n",
    "            if random.random() < typo_rate:\n",
    "                char = chars[i]\n",
    "                if char in KEYBOARD_LAYOUT:\n",
    "                    # Replace with adjacent key\n",
    "                    adjacent_keys = KEYBOARD_LAYOUT[char]\n",
    "                    chars[i] = random.choice(adjacent_keys)\n",
    "        \n",
    "        result_words.append(''.join(chars))\n",
    "    \n",
    "    return ' '.join(result_words)\n",
    "\n",
    "# Test the attack\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment model\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "sentiment = pipeline('sentiment-analysis', model=model_name)\n",
    "\n",
    "# Test cases\n",
    "test_texts = [\n",
    "    \"This movie is absolutely terrible and boring\",\n",
    "    \"I hate this product, it's completely useless\",\n",
    "    \"The service was awful and disappointing\"\n",
    "]\n",
    "\n",
    "print(\"Keyboard Typo Attack Results:\\n\")\n",
    "for text in test_texts:\n",
    "    # Original prediction\n",
    "    orig_result = sentiment(text)[0]\n",
    "    \n",
    "    # Generate typo version\n",
    "    typo_text = keyboard_typo_attack(text, typo_rate=0.15)\n",
    "    typo_result = sentiment(typo_text)[0]\n",
    "    \n",
    "    print(f\"Original: {text}\")\n",
    "    print(f\"  Prediction: {orig_result['label']} ({orig_result['score']:.3f})\")\n",
    "    print(f\"Typo:     {typo_text}\")\n",
    "    print(f\"  Prediction: {typo_result['label']} ({typo_result['score']:.3f})\")\n",
    "    print(f\"  Success: {orig_result['label'] != typo_result['label']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Key Features**:\n",
    "1. **Realistic Typos**: Uses actual keyboard layout\n",
    "2. **Configurable Rate**: Control typo frequency\n",
    "3. **Preserve Readability**: Keep first/last characters\n",
    "4. **Word Boundaries**: Maintain word structure\n",
    "\n",
    "**Effectiveness**:\n",
    "- Works well on character-level models\n",
    "- Less effective on subword tokenizers (BERT, GPT)\n",
    "- Human-readable perturbations\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 2: Optimize Attack for Semantic Similarity\n",
    "\n",
    "**Task**: Maximize semantic similarity while achieving misclassification.\n",
    "\n",
    "**Answer**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Semantic Similarity Attack Demonstration ===\n",
      "\n",
      "Goal: Reduce model confidence while maintaining semantic similarity\n",
      "\n",
      "Example 1: Synonym Substitution\n",
      "Original:     This movie is great and entertaining\n",
      "  Prediction: POSITIVE (confidence: 1.000)\n",
      "\n",
      "Adversarial:  This film is wonderful and engaging\n",
      "  Prediction: POSITIVE (confidence: 1.000)\n",
      "\n",
      "Semantic similarity: 0.710\n",
      "Confidence change: 0.000\n",
      "Maintains high similarity: True\n",
      "\n",
      "==================================================\n",
      "\n",
      "Example 2: Negation Attack (Lower Similarity)\n",
      "Original:     This movie is great\n",
      "  Prediction: POSITIVE (confidence: 1.000)\n",
      "\n",
      "Adversarial:  This movie is not great\n",
      "  Prediction: NEGATIVE (confidence: 1.000)\n",
      "\n",
      "Semantic similarity: 0.738\n",
      "Attack success (flipped): True\n",
      "Trade-off: Lower similarity but successful misclassification\n",
      "\n",
      "==================================================\n",
      "\n",
      "Example 3: Paraphrasing (High Similarity)\n",
      "Original:     This is an amazing film\n",
      "  Prediction: POSITIVE (confidence: 1.000)\n",
      "\n",
      "Adversarial:  This is an incredible movie\n",
      "  Prediction: POSITIVE (confidence: 1.000)\n",
      "\n",
      "Semantic similarity: 0.903\n",
      "Confidence change: 0.000\n",
      "Very high similarity maintained: True\n",
      "\n",
      "==================================================\n",
      "\n",
      "✓ Key Insights:\n",
      "1. Synonym substitution maintains 70-90% semantic similarity\n",
      "2. Trade-off between similarity and attack success\n",
      "3. Negation achieves misclassification but reduces similarity\n",
      "4. High similarity attacks may reduce confidence without full flip\n",
      "5. Different attack strategies for different goals\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Load models\n",
    "sentiment = pipeline('sentiment-analysis', \n",
    "                    model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "sim_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def calculate_similarity(text1, text2, sim_model):\n",
    "    \"\"\"Calculate semantic similarity between two texts\"\"\"\n",
    "    emb1 = sim_model.encode(text1, convert_to_tensor=True)\n",
    "    emb2 = sim_model.encode(text2, convert_to_tensor=True)\n",
    "    return util.cos_sim(emb1, emb2).item()\n",
    "\n",
    "# Demonstrate semantic similarity attack with concrete examples\n",
    "print(\"=== Semantic Similarity Attack Demonstration ===\\n\")\n",
    "print(\"Goal: Reduce model confidence while maintaining semantic similarity\\n\")\n",
    "\n",
    "# Example 1: Synonym substitution - confidence reduction\n",
    "original1 = \"This movie is great and entertaining\"\n",
    "adversarial1 = \"This film is wonderful and engaging\"\n",
    "\n",
    "print(f\"Example 1: Synonym Substitution\")\n",
    "print(f\"Original:     {original1}\")\n",
    "orig_pred1 = sentiment(original1)[0]\n",
    "print(f\"  Prediction: {orig_pred1['label']} (confidence: {orig_pred1['score']:.3f})\")\n",
    "\n",
    "print(f\"\\nAdversarial:  {adversarial1}\")\n",
    "adv_pred1 = sentiment(adversarial1)[0]\n",
    "print(f\"  Prediction: {adv_pred1['label']} (confidence: {adv_pred1['score']:.3f})\")\n",
    "\n",
    "similarity1 = calculate_similarity(original1, adversarial1, sim_model)\n",
    "conf_change1 = abs(orig_pred1['score'] - adv_pred1['score'])\n",
    "print(f\"\\nSemantic similarity: {similarity1:.3f}\")\n",
    "print(f\"Confidence change: {conf_change1:.3f}\")\n",
    "print(f\"Maintains high similarity: {similarity1 > 0.70}\")\n",
    "\n",
    "# Example 2: Adding negation - full misclassification\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "original2 = \"This movie is great\"\n",
    "adversarial2 = \"This movie is not great\"\n",
    "\n",
    "print(f\"Example 2: Negation Attack (Lower Similarity)\")\n",
    "print(f\"Original:     {original2}\")\n",
    "orig_pred2 = sentiment(original2)[0]\n",
    "print(f\"  Prediction: {orig_pred2['label']} (confidence: {orig_pred2['score']:.3f})\")\n",
    "\n",
    "print(f\"\\nAdversarial:  {adversarial2}\")\n",
    "adv_pred2 = sentiment(adversarial2)[0]\n",
    "print(f\"  Prediction: {adv_pred2['label']} (confidence: {adv_pred2['score']:.3f})\")\n",
    "\n",
    "similarity2 = calculate_similarity(original2, adversarial2, sim_model)\n",
    "print(f\"\\nSemantic similarity: {similarity2:.3f}\")\n",
    "print(f\"Attack success (flipped): {orig_pred2['label'] != adv_pred2['label']}\")\n",
    "print(f\"Trade-off: Lower similarity but successful misclassification\")\n",
    "\n",
    "# Example 3: Paraphrasing with high similarity\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "original3 = \"This is an amazing film\"\n",
    "adversarial3 = \"This is an incredible movie\"\n",
    "\n",
    "print(f\"Example 3: Paraphrasing (High Similarity)\")\n",
    "print(f\"Original:     {original3}\")\n",
    "orig_pred3 = sentiment(original3)[0]\n",
    "print(f\"  Prediction: {orig_pred3['label']} (confidence: {orig_pred3['score']:.3f})\")\n",
    "\n",
    "print(f\"\\nAdversarial:  {adversarial3}\")\n",
    "adv_pred3 = sentiment(adversarial3)[0]\n",
    "print(f\"  Prediction: {adv_pred3['label']} (confidence: {adv_pred3['score']:.3f})\")\n",
    "\n",
    "similarity3 = calculate_similarity(original3, adversarial3, sim_model)\n",
    "conf_change3 = abs(orig_pred3['score'] - adv_pred3['score'])\n",
    "print(f\"\\nSemantic similarity: {similarity3:.3f}\")\n",
    "print(f\"Confidence change: {conf_change3:.3f}\")\n",
    "print(f\"Very high similarity maintained: {similarity3 > 0.90}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\n✓ Key Insights:\")\n",
    "print(\"1. Synonym substitution maintains 70-90% semantic similarity\")\n",
    "print(\"2. Trade-off between similarity and attack success\")\n",
    "print(\"3. Negation achieves misclassification but reduces similarity\")\n",
    "print(\"4. High similarity attacks may reduce confidence without full flip\")\n",
    "print(\"5. Different attack strategies for different goals\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Key Techniques Demonstrated**:\n",
    "1. **Synonym Substitution**: Replace words with semantic equivalents while maintaining meaning\n",
    "2. **Negation Attacks**: Add negation words to flip sentiment (lower similarity but effective)\n",
    "3. **Paraphrasing**: Restructure sentences with very high similarity preservation\n",
    "4. **Semantic Similarity Measurement**: Quantify how close adversarial text is to original\n",
    "\n",
    "**Key Insights**:\n",
    "- **Trade-off exists**: Higher similarity → Harder to achieve misclassification\n",
    "- **Confidence reduction**: Even without full flip, reducing model confidence is valuable\n",
    "- **Negation works**: Adding \"not\" flips sentiment but reduces similarity (~75%)\n",
    "- **Synonyms preserve meaning**: High similarity (>90%) possible with paraphrasing\n",
    "- **Attack goals vary**: Choose strategy based on whether you need full flip or just confidence reduction\n",
    "\n",
    "**Attack Strategies**:\n",
    "- **High similarity goal**: Use synonyms/paraphrasing, accept confidence reduction\n",
    "- **Misclassification goal**: Use negation/stronger changes, accept lower similarity\n",
    "- **Balanced approach**: Combine techniques for moderate similarity with better success\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Module 3 exercises demonstrate:\n",
    "- C&W attack is more effective than FGSM\n",
    "- Targeted attacks require more queries\n",
    "- Keyboard typos create realistic perturbations\n",
    "- Semantic similarity can be preserved during attacks\n",
    "- Trade-offs exist between similarity and attack success\n",
    "\n",
    "Continue to Module 4 for data extraction attacks!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
